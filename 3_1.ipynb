{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#create the docs_raw variable from the .json file\n",
    "with open('documents.json','rt') as f_in:\n",
    "    docs_raw = json.load(f_in)\n",
    "\n",
    "documents = []\n",
    "\n",
    "\n",
    "#siccome elastic search vuole tutti i documenti su un livello, mettiamo ad ogni documento il suo corso\n",
    "#prima i documenti erano suddivisi in sezione, in base al corso\n",
    "#guarda le differenze tra docs_raw e documents\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sentence_transformers==2.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this model has 768 length\n",
    "model = SentenceTransformer(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encode(\"this is a simple sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations=[]\n",
    "\n",
    "for doc in documents:\n",
    "    doc[\"text_vector\"] = model.encode(doc[\"text\"]).tolist()\n",
    "    operations.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate the elastic search connection\n",
    "from elasticsearch import Elasticsearch\n",
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "es_client.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a mapping (aka index_settings). It defines how a document is stored and indexed\n",
    "index_settings = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"text\": {\"type\": \"text\"},\n",
    "                \"section\": {\"type\": \"text\"},\n",
    "                \"question\": {\"type\": \"text\"},\n",
    "                \"course\": {\"type\": \"keyword\"},\n",
    "                #tipo -> dense_vector, dimensione -> 768, la metrica di similarità che andrà ad usare\n",
    "                \"text_vector\": {\"type\": \"dense_vector\", \"dims\": 768, \"index\": True, \"similarity\": \"cosine\"}\n",
    "            }\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add documents into index\n",
    "import tqdm\n",
    "#dont run this cell several times, or (idk why) some doc duplicated. If so, try to delete the index ->\n",
    "#es_client.indices.delete(index=index_name)\n",
    "from tqdm.auto import tqdm\n",
    "for doc in tqdm(documents):\n",
    "    try:\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a query\n",
    "\n",
    "search_term = \"windows or mac?\"\n",
    "vector_search_term = model.encode(search_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#il campo \"field\" serve per dire al VDB di andare a cercare nel suddetto campo\n",
    "#il campo \"k\" serve per cercare i k vettori più vicini alla query\n",
    "#il campo \"num_candidates\" serve per indicare in quanti documenti andrà fatta la ricerca\n",
    "\n",
    "query = {\n",
    "    \"field\": \"text_vector\",\n",
    "    \"query_vector\": vector_search_term,\n",
    "    \"k\": 5,\n",
    "    \"num_candidates\": 10000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's search into VDB\n",
    "#il campo \"knn\" serve per indicare \n",
    "#il campo \"source\" serve per indicare quali campi si vuole nella risposta\n",
    "\n",
    "res = es_client.search(index=index_name, knn=query, source=[\"text\",\"section\",\"question\",\"course\"])\n",
    "res['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#per fare una corretta ricerca semantica, dobbiamo andare a trasformare la nostra query in un vettore\n",
    "#quando facciamo una ricerca normale(non semantica), i risultati avranno uno score compreso tra 0 e 1\n",
    "\n",
    "\n",
    "knn_query = {\n",
    "    \"field\": \"text_vector\",\n",
    "    \"query_vector\": vector_search_term,\n",
    "    \"k\":5,\n",
    "    \"num_candidates\": 10000\n",
    "}\n",
    "\n",
    "#il campo \"explain\" serve per avere più informazioni su come lo score è calcolato\n",
    "#si può creare una propria scoring function\n",
    "response = es_client.search(\n",
    "    index=index_name,\n",
    "    query={\n",
    "        \"match\":{\n",
    "            \"course\": \"data-engineering-zoomcamp\"\n",
    "        },\n",
    "    },\n",
    "    knn=knn_query,\n",
    "    source=[\"text\",\"section\",\"question\",\"course\"],\n",
    "    size=5,\n",
    "    explain=True\n",
    ")\n",
    "\n",
    "response['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cella per vedere quanti documenti sono presenti nel VDB\n",
    "\n",
    "search_query = {\n",
    "    \"size\": 10000,\n",
    "    \"query\": {\n",
    "        \"match_all\": {}\n",
    "    }\n",
    "        }\n",
    "    \n",
    "\n",
    "response = es_client.search(index=index_name, body=search_query)\n",
    "len(response['hits']['hits'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
